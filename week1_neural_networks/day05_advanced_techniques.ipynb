{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dba543-43b3-46e3-8c8d-2854c10e3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "==================================================\n",
    "DAY 5: ADVANCED CNN TECHNIQUES\n",
    "Making CNNs production-ready\n",
    "==================================================\n",
    "Date: October 22, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7376e5-b048-4a8e-b36b-43f5ee093e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "‚úÖ Setup complete!\n",
      "Training: 60000 | Test: 10000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SESSION SETUP - RELOAD DATASETS & IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading MNIST dataset...\")\n",
    "\n",
    "# Basic transform\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=basic_transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=basic_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Setup complete!\")\n",
    "print(f\"Training: {len(train_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9555de9b-833d-42e0-9b40-80c704cb2c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART 1: DATA AUGMENTATION - MAKING MODELS MORE ROBUST\n",
      "============================================================\n",
      "\n",
      "THE PROBLEM:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Your model only sees training images in ONE way:\n",
      "- Digit \"7\" always upright\n",
      "- Always centered\n",
      "- Always same size\n",
      "- Always same lighting\n",
      "\n",
      "REAL WORLD:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Images come in many variations:\n",
      "- Slightly rotated\n",
      "- Off-center\n",
      "- Different sizes\n",
      "- Different lighting\n",
      "- Noise, blur, etc.\n",
      "\n",
      "SOLUTION: DATA AUGMENTATION\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Artificially create variations during training:\n",
      "- Rotate images randomly\n",
      "- Shift left/right/up/down\n",
      "- Zoom in/out\n",
      "- Add noise\n",
      "\n",
      "Result: Model learns to handle variations! ‚úÖ\n",
      "\n",
      "Let's see it in action...\n",
      "\n",
      "\n",
      "VISUALIZING DATA AUGMENTATION:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Each version is slightly different!\n",
      "The network will see all these variations during training.\n",
      "This makes it more robust to real-world variations! üéØ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 1: DATA AUGMENTATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PART 1: DATA AUGMENTATION - MAKING MODELS MORE ROBUST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "THE PROBLEM:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Your model only sees training images in ONE way:\n",
    "- Digit \"7\" always upright\n",
    "- Always centered\n",
    "- Always same size\n",
    "- Always same lighting\n",
    "\n",
    "REAL WORLD:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Images come in many variations:\n",
    "- Slightly rotated\n",
    "- Off-center\n",
    "- Different sizes\n",
    "- Different lighting\n",
    "- Noise, blur, etc.\n",
    "\n",
    "SOLUTION: DATA AUGMENTATION\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Artificially create variations during training:\n",
    "- Rotate images randomly\n",
    "- Shift left/right/up/down\n",
    "- Zoom in/out\n",
    "- Add noise\n",
    "\n",
    "Result: Model learns to handle variations! ‚úÖ\n",
    "\n",
    "Let's see it in action...\n",
    "\"\"\")\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Create augmentation pipeline\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),           # Rotate ¬±10 degrees\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),  # Shift up to 10%\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Visualize augmentation\n",
    "print(\"\\nVISUALIZING DATA AUGMENTATION:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get one image from the dataset we loaded earlier\n",
    "original_image, label = test_dataset[0]\n",
    "\n",
    "# Convert to PIL for augmentation\n",
    "# MNIST images are already tensors, so convert back to PIL\n",
    "pil_image = transforms.ToPILImage()(original_image)\n",
    "\n",
    "# Apply augmentation multiple times to same image\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(f'Same Digit \"{label}\" with Different Augmentations', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(10):\n",
    "    # Apply augmentation (each time will be different!)\n",
    "    augmented = augmentation_transform(pil_image)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(augmented.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Variation {i+1}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Each version is slightly different!\")\n",
    "print(\"The network will see all these variations during training.\")\n",
    "print(\"This makes it more robust to real-world variations! üéØ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faed223e-06c2-4e84-9f40-775d477923cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 2: TRAINING CNN WITH DATA AUGMENTATION\n",
      "============================================================\n",
      "\n",
      "Training CNN WITH data augmentation...\n",
      "(Network sees rotated/shifted versions each epoch)\n",
      "\n",
      "This will take 3-4 minutes...\n",
      "\n",
      "Epoch [1/3] Batch [200/938] Loss: 0.5524 Acc: 69.01%\n",
      "Epoch [1/3] Batch [400/938] Loss: 0.4664 Acc: 79.34%\n",
      "Epoch [1/3] Batch [600/938] Loss: 0.1694 Acc: 83.83%\n",
      "Epoch [1/3] Batch [800/938] Loss: 0.1913 Acc: 86.34%\n",
      "\n",
      "============================================================\n",
      "EPOCH 1 COMPLETE\n",
      "Loss: 0.3927 | Training Accuracy: 87.53%\n",
      "============================================================\n",
      "\n",
      "Epoch [2/3] Batch [200/938] Loss: 0.2067 Acc: 95.16%\n",
      "Epoch [2/3] Batch [400/938] Loss: 0.1855 Acc: 95.23%\n",
      "Epoch [2/3] Batch [600/938] Loss: 0.1042 Acc: 95.20%\n",
      "Epoch [2/3] Batch [800/938] Loss: 0.0870 Acc: 95.35%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2 COMPLETE\n",
      "Loss: 0.1457 | Training Accuracy: 95.46%\n",
      "============================================================\n",
      "\n",
      "Epoch [3/3] Batch [200/938] Loss: 0.1626 Acc: 96.27%\n",
      "Epoch [3/3] Batch [400/938] Loss: 0.0310 Acc: 96.36%\n",
      "Epoch [3/3] Batch [600/938] Loss: 0.1238 Acc: 96.34%\n",
      "Epoch [3/3] Batch [800/938] Loss: 0.0564 Acc: 96.46%\n",
      "\n",
      "============================================================\n",
      "EPOCH 3 COMPLETE\n",
      "Loss: 0.1146 | Training Accuracy: 96.53%\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úÖ Training with augmentation complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 2: TRAINING WITH DATA AUGMENTATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PART 2: TRAINING CNN WITH DATA AUGMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load training data WITH augmentation\n",
    "train_dataset_augmented = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=False,  # Already downloaded\n",
    "    transform=augmented_transform\n",
    ")\n",
    "\n",
    "train_loader_augmented = DataLoader(train_dataset_augmented, batch_size=64, shuffle=True)\n",
    "\n",
    "# Use same CNN architecture from Day 4\n",
    "class CNN_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model_augmented = CNN_MNIST()\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_augmented.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\nTraining CNN WITH data augmentation...\")\n",
    "print(\"(Network sees rotated/shifted versions each epoch)\")\n",
    "print(\"\\nThis will take 3-4 minutes...\\n\")\n",
    "\n",
    "# Train for 3 epochs\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_augmented.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader_augmented):\n",
    "        outputs = model_augmented(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 200 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx+1}/{len(train_loader_augmented)}] \"\n",
    "                  f\"Loss: {loss.item():.4f} Acc: {100*correct/total:.2f}%\")\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader_augmented)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1} COMPLETE\")\n",
    "    print(f\"Loss: {avg_loss:.4f} | Training Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Training with augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d73e863-846e-43a0-8fe0-128e3b5f6d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 3: TESTING: AUGMENTED vs NON-AUGMENTED MODEL\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESULTS COMPARISON:\n",
      "============================================================\n",
      "\n",
      "Day 4 CNN (no augmentation):  98.92% test accuracy\n",
      "Day 5 CNN (with augmentation): 98.97% test accuracy\n",
      "\n",
      "‚úÖ IMPROVEMENT: +0.05 percentage points!\n",
      "Augmentation helped! 9897 correct out of 10,000!\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHT:\n",
      "============================================================\n",
      "\n",
      "Training accuracy: 96.49% (lower than before)\n",
      "Test accuracy: 98.97% \n",
      "\n",
      "Lower training accuracy + similar/better test accuracy = GOOD!\n",
      "This means the model is GENERALIZING, not just memorizing.\n",
      "\n",
      "On more complex datasets (like your Project 1 safety images),\n",
      "data augmentation will be CRITICAL for good performance! ‚úÖ\n",
      "\n",
      "Why augmentation matters more for real projects:\n",
      "- Limited data (maybe only 500-1000 safety images)\n",
      "- More variation in real world (lighting, angles, distances)\n",
      "- Augmentation effectively 10√ó your dataset size\n",
      "- Prevents overfitting on small datasets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 3: TESTING AUGMENTED MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PART 3: TESTING: AUGMENTED vs NON-AUGMENTED MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test augmented model\n",
    "model_augmented.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model_augmented(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "augmented_accuracy = 100 * correct / total\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDay 4 CNN (no augmentation):  98.92% test accuracy\")\n",
    "print(f\"Day 5 CNN (with augmentation): {augmented_accuracy:.2f}% test accuracy\")\n",
    "\n",
    "if augmented_accuracy > 98.92:\n",
    "    improvement = augmented_accuracy - 98.92\n",
    "    print(f\"\\n‚úÖ IMPROVEMENT: +{improvement:.2f} percentage points!\")\n",
    "    print(f\"Augmentation helped! {int((augmented_accuracy/100) * 10000)} correct out of 10,000!\")\n",
    "elif augmented_accuracy >= 98.5:\n",
    "    print(f\"\\n‚úÖ EXCELLENT: Still very high accuracy!\")\n",
    "    print(f\"Augmentation maintained strong performance!\")\n",
    "    print(f\"{int((augmented_accuracy/100) * 10000)} correct out of 10,000!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Slightly lower, but this is normal for MNIST\")\n",
    "    print(\"MNIST is too simple - augmentation benefits show more on complex datasets!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Training accuracy: 96.49% (lower than before)\n",
    "Test accuracy: {:.2f}% \n",
    "\n",
    "Lower training accuracy + similar/better test accuracy = GOOD!\n",
    "This means the model is GENERALIZING, not just memorizing.\n",
    "\n",
    "On more complex datasets (like your Project 1 safety images),\n",
    "data augmentation will be CRITICAL for good performance! ‚úÖ\n",
    "\n",
    "Why augmentation matters more for real projects:\n",
    "- Limited data (maybe only 500-1000 safety images)\n",
    "- More variation in real world (lighting, angles, distances)\n",
    "- Augmentation effectively 10√ó your dataset size\n",
    "- Prevents overfitting on small datasets\n",
    "\"\"\".format(augmented_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b75abd2-47c5-43e9-8909-918c284b3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART 4: TRANSFER LEARNING - THE SECRET WEAPON\n",
      "============================================================\n",
      "\n",
      "THE PROBLEM WITH TRAINING FROM SCRATCH:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "To train a good CNN, you typically need:\n",
      "- 100,000+ images\n",
      "- Days/weeks of training time\n",
      "- Expensive GPUs\n",
      "- Huge computational cost\n",
      "\n",
      "YOUR PROJECT 1 REALITY:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "- Only 500-1,000 safety equipment images\n",
      "- Limited time\n",
      "- CPU or basic GPU\n",
      "- Can't train from scratch!\n",
      "\n",
      "THE SOLUTION: TRANSFER LEARNING\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Use a model ALREADY TRAINED on millions of images!\n",
      "\n",
      "ImageNet dataset:\n",
      "- 1.4 MILLION images\n",
      "- 1,000 categories (dogs, cats, cars, planes, etc.)\n",
      "- Trained for weeks on powerful GPUs\n",
      "\n",
      "These models learned to detect:\n",
      "‚úÖ Edges\n",
      "‚úÖ Corners\n",
      "‚úÖ Textures\n",
      "‚úÖ Shapes\n",
      "‚úÖ Objects\n",
      "‚úÖ Complex patterns\n",
      "\n",
      "THESE FEATURES ARE UNIVERSAL!\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "The features that detect \"dog\" can also detect \"hard hat\"!\n",
      "The features that detect \"car\" can also detect \"safety vest\"!\n",
      "\n",
      "HOW TRANSFER LEARNING WORKS:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "1. Take pre-trained model (trained on ImageNet)\n",
      "2. Remove last layer (1,000 outputs for ImageNet)\n",
      "3. Add YOUR layer (e.g., 3 outputs: helmet, vest, gloves)\n",
      "4. Freeze early layers (keep learned features)\n",
      "5. Train only last layer on YOUR data\n",
      "6. Result: Great performance with limited data! ‚úÖ\n",
      "\n",
      "TRAINING TIME:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "- From scratch: 10,000+ images, 2-3 days training\n",
      "- Transfer learning: 500 images, 30 minutes training\n",
      "\n",
      "THIS IS HOW PROFESSIONALS DO IT! üéØ\n",
      "\n",
      "\n",
      "Let's see transfer learning in action...\n",
      "We'll use a pre-trained ResNet18 model!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 4: TRANSFER LEARNING - THE GAME CHANGER\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PART 4: TRANSFER LEARNING - THE SECRET WEAPON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "THE PROBLEM WITH TRAINING FROM SCRATCH:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "To train a good CNN, you typically need:\n",
    "- 100,000+ images\n",
    "- Days/weeks of training time\n",
    "- Expensive GPUs\n",
    "- Huge computational cost\n",
    "\n",
    "YOUR PROJECT 1 REALITY:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "- Only 500-1,000 safety equipment images\n",
    "- Limited time\n",
    "- CPU or basic GPU\n",
    "- Can't train from scratch!\n",
    "\n",
    "THE SOLUTION: TRANSFER LEARNING\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Use a model ALREADY TRAINED on millions of images!\n",
    "\n",
    "ImageNet dataset:\n",
    "- 1.4 MILLION images\n",
    "- 1,000 categories (dogs, cats, cars, planes, etc.)\n",
    "- Trained for weeks on powerful GPUs\n",
    "\n",
    "These models learned to detect:\n",
    "‚úÖ Edges\n",
    "‚úÖ Corners\n",
    "‚úÖ Textures\n",
    "‚úÖ Shapes\n",
    "‚úÖ Objects\n",
    "‚úÖ Complex patterns\n",
    "\n",
    "THESE FEATURES ARE UNIVERSAL!\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "The features that detect \"dog\" can also detect \"hard hat\"!\n",
    "The features that detect \"car\" can also detect \"safety vest\"!\n",
    "\n",
    "HOW TRANSFER LEARNING WORKS:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. Take pre-trained model (trained on ImageNet)\n",
    "2. Remove last layer (1,000 outputs for ImageNet)\n",
    "3. Add YOUR layer (e.g., 3 outputs: helmet, vest, gloves)\n",
    "4. Freeze early layers (keep learned features)\n",
    "5. Train only last layer on YOUR data\n",
    "6. Result: Great performance with limited data! ‚úÖ\n",
    "\n",
    "TRAINING TIME:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "- From scratch: 10,000+ images, 2-3 days training\n",
    "- Transfer learning: 500 images, 30 minutes training\n",
    "\n",
    "THIS IS HOW PROFESSIONALS DO IT! üéØ\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nLet's see transfer learning in action...\")\n",
    "print(\"We'll use a pre-trained ResNet18 model!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237117fb-55cc-4397-a018-973d520a3d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING PRE-TRAINED ResNet18\n",
      "============================================================\n",
      "\n",
      "Downloading ResNet18 (pre-trained on 1.4M images)...\n",
      "(First time only - ~45MB download)\n",
      "\n",
      "‚úÖ ResNet18 loaded!\n",
      "\n",
      "This model was trained on ImageNet:\n",
      "  - 1.4 million images\n",
      "  - 1,000 categories\n",
      "  - Trained for weeks on powerful GPUs\n",
      "  - Cost: ~$10,000+ in compute\n",
      "\n",
      "You just got it for FREE in 30 seconds! üéâ\n",
      "\n",
      "============================================================\n",
      "ResNet18 ARCHITECTURE:\n",
      "============================================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOADING A PRE-TRAINED MODEL (ResNet18)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOADING PRE-TRAINED ResNet18\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load ResNet18 pre-trained on ImageNet (UPDATED SYNTAX!)\n",
    "print(\"\\nDownloading ResNet18 (pre-trained on 1.4M images)...\")\n",
    "print(\"(First time only - ~45MB download)\")\n",
    "\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "print(\"\\n‚úÖ ResNet18 loaded!\")\n",
    "print(\"\\nThis model was trained on ImageNet:\")\n",
    "print(\"  - 1.4 million images\")\n",
    "print(\"  - 1,000 categories\")\n",
    "print(\"  - Trained for weeks on powerful GPUs\")\n",
    "print(\"  - Cost: ~$10,000+ in compute\")\n",
    "print(\"\\nYou just got it for FREE in 30 seconds! üéâ\")\n",
    "\n",
    "# Let's look at the architecture\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ResNet18 ARCHITECTURE:\")\n",
    "print(\"=\" * 60)\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb5c152-72df-4edb-9313-130a4bab6b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODIFYING ResNet18 FOR MNIST (10 DIGITS)\n",
      "============================================================\n",
      "\n",
      "ORIGINAL ResNet18:\n",
      "- Input: 3 channels (RGB color images)\n",
      "- Output: 1,000 classes (ImageNet categories)\n",
      "\n",
      "OUR MNIST TASK:\n",
      "- Input: 1 channel (grayscale)\n",
      "- Output: 10 classes (digits 0-9)\n",
      "\n",
      "MODIFICATIONS NEEDED:\n",
      "1. Change first layer: 3 channels ‚Üí 1 channel\n",
      "2. Change last layer: 1,000 outputs ‚Üí 10 outputs\n",
      "3. Freeze early layers (keep ImageNet features)\n",
      "4. Train only last layer on MNIST\n",
      "\n",
      "\n",
      "ResNet18 final layer has 512 input features\n",
      "Changed output layer: 512 ‚Üí 10 (for 10 digits)\n",
      "\n",
      "Freezing all layers except final classification layer...\n",
      "\n",
      "============================================================\n",
      "PARAMETER BREAKDOWN:\n",
      "============================================================\n",
      "Total parameters: 11,175,370\n",
      "Frozen parameters: 11,170,240\n",
      "Trainable parameters: 5,130\n",
      "\n",
      "We're only training 5,130 parameters!\n",
      "The rest (11,170,240) are FROZEN (pre-trained from ImageNet)\n",
      "\n",
      "‚úÖ ResNet18 adapted for MNIST!\n",
      "\n",
      "This is EXACTLY how you'll adapt YOLO for Project 1:\n",
      "  - Keep pre-trained feature extractors\n",
      "  - Only train final layer for YOUR classes\n",
      "  - Fast training + great results! üéØ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ADAPTING ResNet18 FOR MNIST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODIFYING ResNet18 FOR MNIST (10 DIGITS)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "ORIGINAL ResNet18:\n",
    "- Input: 3 channels (RGB color images)\n",
    "- Output: 1,000 classes (ImageNet categories)\n",
    "\n",
    "OUR MNIST TASK:\n",
    "- Input: 1 channel (grayscale)\n",
    "- Output: 10 classes (digits 0-9)\n",
    "\n",
    "MODIFICATIONS NEEDED:\n",
    "1. Change first layer: 3 channels ‚Üí 1 channel\n",
    "2. Change last layer: 1,000 outputs ‚Üí 10 outputs\n",
    "3. Freeze early layers (keep ImageNet features)\n",
    "4. Train only last layer on MNIST\n",
    "\"\"\")\n",
    "\n",
    "# Modify first layer for grayscale (1 channel instead of 3)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Get number of features before final layer\n",
    "num_features = resnet18.fc.in_features\n",
    "print(f\"\\nResNet18 final layer has {num_features} input features\")\n",
    "\n",
    "# Replace final layer: 1000 outputs ‚Üí 10 outputs\n",
    "resnet18.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "print(f\"Changed output layer: {num_features} ‚Üí 10 (for 10 digits)\")\n",
    "\n",
    "# FREEZE all layers except the last one\n",
    "print(\"\\nFreezing all layers except final classification layer...\")\n",
    "for name, param in resnet18.named_parameters():\n",
    "    if 'fc' not in name:  # Freeze everything except 'fc' (final layer)\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in resnet18.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in resnet18.parameters())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PARAMETER BREAKDOWN:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nWe're only training {trainable_params:,} parameters!\")\n",
    "print(\"The rest ({:,}) are FROZEN (pre-trained from ImageNet)\".format(total_params - trainable_params))\n",
    "\n",
    "print(\"\\n‚úÖ ResNet18 adapted for MNIST!\")\n",
    "print(\"\\nThis is EXACTLY how you'll adapt YOLO for Project 1:\")\n",
    "print(\"  - Keep pre-trained feature extractors\")\n",
    "print(\"  - Only train final layer for YOUR classes\")\n",
    "print(\"  - Fast training + great results! üéØ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689fcdd7-a018-428d-8ab6-d67806ec4306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING ResNet18 ON MNIST (TRANSFER LEARNING)\n",
      "============================================================\n",
      "\n",
      "Training ONLY the last layer (5,130 parameters)...\n",
      "Using features from 11 million pre-trained parameters!\n",
      "\n",
      "This should be FAST - only 2 epochs needed!\n",
      "\n",
      "Epoch [1/2] Batch [200/938] Loss: 0.3258 Acc: 80.50%\n",
      "Epoch [1/2] Batch [400/938] Loss: 0.2430 Acc: 86.38%\n",
      "Epoch [1/2] Batch [600/938] Loss: 0.2846 Acc: 88.75%\n",
      "Epoch [1/2] Batch [800/938] Loss: 0.1838 Acc: 90.25%\n",
      "\n",
      "============================================================\n",
      "EPOCH 1 COMPLETE\n",
      "Loss: 0.3792 | Training Accuracy: 90.88%\n",
      "============================================================\n",
      "\n",
      "Epoch [2/2] Batch [200/938] Loss: 0.1444 Acc: 95.15%\n",
      "Epoch [2/2] Batch [400/938] Loss: 0.2256 Acc: 95.16%\n",
      "Epoch [2/2] Batch [600/938] Loss: 0.0852 Acc: 95.25%\n",
      "Epoch [2/2] Batch [800/938] Loss: 0.1661 Acc: 95.30%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2 COMPLETE\n",
      "Loss: 0.1619 | Training Accuracy: 95.36%\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úÖ Transfer learning training complete!\n",
      "\n",
      "Notice: High accuracy in just 2 epochs!\n",
      "This is the POWER of pre-trained features! üöÄ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRAINING ResNet18 WITH TRANSFER LEARNING\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING ResNet18 ON MNIST (TRANSFER LEARNING)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MNIST images are 28√ó28, but ResNet expects 224√ó224\n",
    "# We need to resize them\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to ResNet's expected input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Reload MNIST with resizing\n",
    "train_dataset_resized = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=resize_transform\n",
    ")\n",
    "\n",
    "test_dataset_resized = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=resize_transform\n",
    ")\n",
    "\n",
    "train_loader_resized = DataLoader(train_dataset_resized, batch_size=64, shuffle=True)\n",
    "test_loader_resized = DataLoader(test_dataset_resized, batch_size=64, shuffle=False)\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only optimize the parameters that require gradients (the last layer!)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet18.parameters()), lr=0.001)\n",
    "\n",
    "print(\"\\nTraining ONLY the last layer (5,130 parameters)...\")\n",
    "print(\"Using features from 11 million pre-trained parameters!\")\n",
    "print(\"\\nThis should be FAST - only 2 epochs needed!\\n\")\n",
    "\n",
    "# Train for just 2 epochs (transfer learning is fast!)\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    resnet18.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader_resized):\n",
    "        outputs = resnet18(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 200 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx+1}/{len(train_loader_resized)}] \"\n",
    "                  f\"Loss: {loss.item():.4f} Acc: {100*correct/total:.2f}%\")\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader_resized)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1} COMPLETE\")\n",
    "    print(f\"Loss: {avg_loss:.4f} | Training Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Transfer learning training complete!\")\n",
    "print(\"\\nNotice: High accuracy in just 2 epochs!\")\n",
    "print(\"This is the POWER of pre-trained features! üöÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b437c6-1460-4966-8290-5c3473f7aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING ResNet18 ON NEW IMAGES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TRANSFER LEARNING RESULTS:\n",
      "============================================================\n",
      "\n",
      "ResNet18 (transfer learning): 96.50% test accuracy\n",
      "Training time: ~2 epochs (~10-15 minutes on CPU)\n",
      "Parameters trained: Only 5,130 out of 11,175,370!\n",
      "\n",
      "This is the POWER of transfer learning! ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TESTING ResNet18 TRANSFER LEARNING\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING ResNet18 ON NEW IMAGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "resnet18.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_resized:\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "resnet_accuracy = 100 * correct / total\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSFER LEARNING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResNet18 (transfer learning): {resnet_accuracy:.2f}% test accuracy\")\n",
    "print(f\"Training time: ~2 epochs (~10-15 minutes on CPU)\")\n",
    "print(f\"Parameters trained: Only 5,130 out of 11,175,370!\")\n",
    "print(f\"\\nThis is the POWER of transfer learning! ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90e74f-371c-4331-b734-1786db665fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "==================================================\n",
    "DAY 5 COMPLETE + DAY 6 PREVIEW\n",
    "==================================================\n",
    "Date: October 22, 2025\n",
    "Total Time: ~5 hours (including GitHub setup)\n",
    "\n",
    "DAY 5 ACCOMPLISHMENTS:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚úÖ Data Augmentation\n",
    "   - Learned rotation, translation, zoom techniques\n",
    "   - Applied to MNIST\n",
    "   - Understood when/why augmentation helps\n",
    "\n",
    "‚úÖ Batch Normalization & Dropout\n",
    "   - Understood regularization techniques\n",
    "   - Prevents overfitting\n",
    "\n",
    "‚úÖ Transfer Learning\n",
    "   - Loaded pre-trained ResNet18 (11M parameters)\n",
    "   - Froze 11,170,240 parameters\n",
    "   - Trained only 5,130 parameters\n",
    "   - Achieved 95.70% accuracy\n",
    "   - CRITICAL technique for Project 1!\n",
    "\n",
    "‚úÖ Model Saving/Loading\n",
    "   - Can save trained models\n",
    "   - Deploy for inference\n",
    "\n",
    "‚úÖ GitHub Setup\n",
    "   - Created ML-Learning-Journey repository\n",
    "   - Pushed Week 1 work\n",
    "   - Professional portfolio started!\n",
    "\n",
    "KEY INSIGHT:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Transfer learning = secret weapon for limited data.\n",
    "Will be ESSENTIAL for Project 1 (safety detection).\n",
    "\n",
    "RESULTS SUMMARY:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Day 3: Regular NN      ‚Üí 91.28% accuracy\n",
    "Day 4: CNN             ‚Üí 98.92% accuracy\n",
    "Day 5: ResNet Transfer ‚Üí 95.70% accuracy\n",
    "\n",
    "==================================================\n",
    "DAY 6 PREVIEW: CIFAR-10 PRACTICE PROJECT\n",
    "==================================================\n",
    "\n",
    "TOMORROW'S PLAN:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Build complete image classifier for CIFAR-10\n",
    "- 10 classes (airplane, car, bird, cat, deer, dog, frog, horse, ship, truck)\n",
    "- 60,000 images (32√ó32 RGB)\n",
    "- Apply ALL Week 1 skills\n",
    "- First independent project!\n",
    "\n",
    "WHAT I'LL DO:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. Load & explore CIFAR-10 dataset\n",
    "2. Design CNN architecture (RGB input)\n",
    "3. Implement data augmentation\n",
    "4. Train with proper pipeline\n",
    "5. Evaluate performance (confusion matrix)\n",
    "6. Iterate to improve (target 75-80% accuracy)\n",
    "\n",
    "WHY IT MATTERS:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "- First complete end-to-end project\n",
    "- Practice making architectural decisions\n",
    "- Build confidence for Project 1\n",
    "- Learn iterative improvement process\n",
    "\n",
    "TIME ESTIMATE: 4-5 hours\n",
    "\n",
    "PREPARATION:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "- Review CNN architecture (Day 4)\n",
    "- Review data augmentation (Day 5)\n",
    "- Rest well tonight (let concepts solidify!)\n",
    "- Come back fresh tomorrow\n",
    "\n",
    "STATUS: Ready for Day 6! üöÄ\n",
    "\n",
    "==================================================\n",
    "WEEK 1 PROGRESS: 5/7 days complete (71%)\n",
    "NEXT SESSION: Day 6 - CIFAR-10 Classifier\n",
    "=================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
