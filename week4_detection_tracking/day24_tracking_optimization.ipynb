{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206917f6-5b82-4076-8e91-ae8ae76ba3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "ML LEARNING JOURNEY - DAY 24\n",
    "==================================================\n",
    "Week: 4 of 24\n",
    "Day: 24 of 168\n",
    "Date: November 19, 2025\n",
    "Topic: Tracking Optimization & People Counting\n",
    "Overall Progress: 14.3%\n",
    "\n",
    "Week 4: Detection & Tracking Foundation\n",
    "‚úÖ Day 22: Project Planning & Architecture (COMPLETED)\n",
    "‚úÖ Day 23: Multi-Object Tracking (DeepSORT) (COMPLETED)\n",
    "üîÑ Day 24: Tracking Optimization (TODAY!)\n",
    "‚¨ú Day 25: Video Processing Pipeline\n",
    "‚¨ú Day 26: Testing & Performance\n",
    "‚¨ú Day 27: Code Cleanup & Modularization\n",
    "‚¨ú Day 28: Week 4 Review\n",
    "\n",
    "Progress: 43% (3/7 days)\n",
    "\n",
    "==================================================\n",
    "üéØ Week 4 Project: Security System - Detection & Tracking\n",
    "- Optimize tracking parameters for security scenarios\n",
    "- Implement people counting (entry/exit)\n",
    "- Handle occlusions and re-identification\n",
    "- Define zones for monitoring\n",
    "- Achieve consistent 30 FPS performance\n",
    "\n",
    "üéØ Today's Learning Objectives:\n",
    "1. Tune DeepSORT parameters (max_age, n_init, IOU threshold)\n",
    "2. Implement line-crossing detection for people counting\n",
    "3. Handle occlusions robustly (maintain IDs through disappearance)\n",
    "4. Create zone-based monitoring (restricted areas)\n",
    "5. Count people entering and exiting specific areas\n",
    "6. Optimize for different scenarios (crowded, sparse, occlusions)\n",
    "7. Measure tracking accuracy and ID consistency\n",
    "\n",
    "üìö Today's Structure:\n",
    "   Part 1 (2h): Parameter Tuning & Occlusion Handling\n",
    "   Part 2 (2h): People Counting System\n",
    "   Part 3 (2h): Zone-Based Monitoring\n",
    "   Part 4 (1h): Testing & Summary\n",
    "\n",
    "üéØ SUCCESS CRITERIA:\n",
    "   ‚úÖ Tracking parameters optimized (tested scenarios)\n",
    "   ‚úÖ Occlusions handled (IDs maintained through disappearance)\n",
    "   ‚úÖ Line-crossing detection working (entry/exit counting)\n",
    "   ‚úÖ People counting accurate (¬±5% error)\n",
    "   ‚úÖ Zone monitoring implemented (restricted areas)\n",
    "   ‚úÖ Direction detection working (in vs out)\n",
    "   ‚úÖ Performance maintained (25-30 FPS)\n",
    "   ‚úÖ Ready for video processing pipeline (Day 25)\n",
    "==================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb07772b-9c7f-459d-81c0-ef9725eebe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing required libraries...\n",
      "‚è±Ô∏è  This should be quick (most already installed)...\n",
      "\n",
      "Checking ultralytics...\n",
      "Checking deep-sort-realtime...\n",
      "Checking opencv-python...\n",
      "Checking numpy...\n",
      "Checking pandas...\n",
      "Checking matplotlib...\n",
      "Checking scipy...\n",
      "\n",
      "‚úÖ All libraries ready!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö IMPORTING LIBRARIES\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/jy/mnc51c3n13n45tk4xypjbmtc0000gn/T/ipykernel_9612/1940272222.py\", line 54, in <module>\n",
      "    from ultralytics import YOLO\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ultralytics/__init__.py\", line 13, in <module>\n",
      "    from ultralytics.utils import ASSETS, SETTINGS\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/ultralytics/utils/__init__.py\", line 25, in <module>\n",
      "    import torch\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/daneaudrey/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/daneaudrey/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "üìä Library versions:\n",
      "   ‚Ä¢ OpenCV: 4.12.0\n",
      "   ‚Ä¢ NumPy: 2.0.2\n",
      "   ‚Ä¢ Pandas: 2.3.3\n",
      "   ‚Ä¢ Ultralytics: Installed ‚úì\n",
      "   ‚Ä¢ DeepSORT: Installed ‚úì\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# INSTALL REQUIRED LIBRARIES\n",
    "# ==================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üì¶ Installing required libraries...\")\n",
    "print(\"‚è±Ô∏è  This should be quick (most already installed)...\\n\")\n",
    "\n",
    "packages = [\n",
    "    'ultralytics',\n",
    "    'deep-sort-realtime',\n",
    "    'opencv-python',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'matplotlib',\n",
    "    'scipy'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Checking {package}...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '-q'])\n",
    "\n",
    "print(\"\\n‚úÖ All libraries ready!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# ==================================================\n",
    "# IMPORT LIBRARIES\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö IMPORTING LIBRARIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "import json\n",
    "\n",
    "# Data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Computer vision\n",
    "import cv2\n",
    "\n",
    "# Deep learning\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Tracking\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nüìä Library versions:\")\n",
    "print(f\"   ‚Ä¢ OpenCV: {cv2.__version__}\")\n",
    "print(f\"   ‚Ä¢ NumPy: {np.__version__}\")\n",
    "print(f\"   ‚Ä¢ Pandas: {pd.__version__}\")\n",
    "print(\"   ‚Ä¢ Ultralytics: Installed ‚úì\")\n",
    "print(\"   ‚Ä¢ DeepSORT: Installed ‚úì\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd162f5-a3df-422d-aabe-f1afd806c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö PART 1: PARAMETER TUNING & OCCLUSION HANDLING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö PART 1: PARAMETER TUNING & OCCLUSION HANDLING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ea8d20-d626-4c68-b31e-963b1fc17a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.1: Understanding DeepSORT Parameters\n",
      "================================================================================\n",
      "\n",
      "üìä PARAMETER COMPARISON TABLE:\n",
      "\n",
      "Parameter        | Default | Crowded | Sparse  | High Occlusion | Fast Moving\n",
      "-----------------|---------|---------|---------|----------------|------------\n",
      "max_age          |   30    |  20-30  |  15-20  |     40-60      |   10-15\n",
      "n_init           |    3    |   3-4   |   2-3   |      4-5       |     2\n",
      "max_iou_distance |  0.7    | 0.6-0.7 | 0.7-0.8 |    0.5-0.6     |  0.7-0.8\n",
      "max_cosine_dist  |  0.2    |  0.15   |  0.25   |      0.15      |    0.25\n",
      "nn_budget        |  100    |   100   |   50    |      150       |    50\n",
      "\n",
      "Recommendation for Security System (Office/Factory):\n",
      "- Start with: max_age=30, n_init=3, max_iou_distance=0.7\n",
      "- Tune based on specific environment\n",
      "- Test with real footage from deployment location\n",
      "\n",
      "\n",
      "‚úÖ Exercise 1.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.1: UNDERSTAND DEEPSORT PARAMETERS\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.1: Understanding DeepSORT Parameters\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: DeepSORT Critical Parameters\n",
    "\n",
    "The three most important parameters for tuning:\n",
    "\n",
    "1. max_age (Default: 30)\n",
    "   ‚Ä¢ How many frames to keep a track without detection\n",
    "   ‚Ä¢ Higher = More robust to occlusions (but more false positives)\n",
    "   ‚Ä¢ Lower = Faster deletion (but IDs lost easily)\n",
    "   ‚Ä¢ Formula: max_age = expected_occlusion_time * FPS\n",
    "   ‚Ä¢ Example: 1 second occlusion @ 30fps ‚Üí max_age=30\n",
    "\n",
    "2. n_init (Default: 3)\n",
    "   ‚Ä¢ Consecutive detections needed to confirm a track\n",
    "   ‚Ä¢ Higher = Fewer false tracks (but slower confirmation)\n",
    "   ‚Ä¢ Lower = Faster confirmation (but more false positives)\n",
    "   ‚Ä¢ Typically: 2-5 frames\n",
    "\n",
    "3. max_iou_distance (Default: 0.7)\n",
    "   ‚Ä¢ Threshold for matching based on bounding box overlap\n",
    "   ‚Ä¢ IOU = Intersection over Union\n",
    "   ‚Ä¢ Lower = Stricter matching (fewer ID switches)\n",
    "   ‚Ä¢ Higher = More lenient (more matches, potential errors)\n",
    "   ‚Ä¢ Range: 0.5-0.9\n",
    "\n",
    "Additional Parameters:\n",
    "\n",
    "4. max_cosine_distance (Default: 0.2)\n",
    "   ‚Ä¢ Threshold for appearance matching\n",
    "   ‚Ä¢ Based on ReID embedding similarity\n",
    "   ‚Ä¢ Lower = Objects must look very similar\n",
    "   ‚Ä¢ Higher = More lenient appearance matching\n",
    "\n",
    "5. nn_budget (Default: 100)\n",
    "   ‚Ä¢ Number of appearance features to keep per track\n",
    "   ‚Ä¢ Higher = Better re-identification (but more memory)\n",
    "   ‚Ä¢ Lower = Less memory (but worse re-ID)\n",
    "\n",
    "==================================================\n",
    "\n",
    "PARAMETER TUNING GUIDELINES:\n",
    "\n",
    "Scenario: Crowded Areas (Mall, Station)\n",
    "‚îú‚îÄ‚îÄ max_age: 20-30 (frequent occlusions)\n",
    "‚îú‚îÄ‚îÄ n_init: 3-4 (reduce false positives)\n",
    "‚îú‚îÄ‚îÄ max_iou_distance: 0.6-0.7 (strict matching)\n",
    "‚îî‚îÄ‚îÄ Goal: Reduce ID switches in crowds\n",
    "\n",
    "Scenario: Sparse Areas (Office Hallway)\n",
    "‚îú‚îÄ‚îÄ max_age: 15-20 (people rarely hidden)\n",
    "‚îú‚îÄ‚îÄ n_init: 2-3 (fast confirmation)\n",
    "‚îú‚îÄ‚îÄ max_iou_distance: 0.7-0.8 (lenient)\n",
    "‚îî‚îÄ‚îÄ Goal: Quick tracking, smooth experience\n",
    "\n",
    "Scenario: High Occlusion (Factory, Warehouse)\n",
    "‚îú‚îÄ‚îÄ max_age: 40-60 (objects frequently hidden)\n",
    "‚îú‚îÄ‚îÄ n_init: 4-5 (confirm before showing ID)\n",
    "‚îú‚îÄ‚îÄ max_iou_distance: 0.5-0.6 (very strict)\n",
    "‚îî‚îÄ‚îÄ Goal: Maintain IDs through long occlusions\n",
    "\n",
    "Scenario: Fast Moving Objects (Entrance/Exit)\n",
    "‚îú‚îÄ‚îÄ max_age: 10-15 (people pass quickly)\n",
    "‚îú‚îÄ‚îÄ n_init: 2 (immediate confirmation)\n",
    "‚îú‚îÄ‚îÄ max_iou_distance: 0.7-0.8 (allow fast motion)\n",
    "‚îî‚îÄ‚îÄ Goal: Count people before they leave frame\n",
    "\n",
    "==================================================\n",
    "\n",
    "IMPACT ON PERFORMANCE:\n",
    "\n",
    "Speed Impact:\n",
    "- max_age: Minimal (just checks counter)\n",
    "- n_init: Minimal (just checks counter)\n",
    "- max_iou_distance: None (threshold only)\n",
    "- nn_budget: High budget = more memory, slightly slower\n",
    "- Overall: Parameter tuning doesn't significantly affect FPS\n",
    "\n",
    "Accuracy Impact:\n",
    "- max_age too low ‚Üí Lost tracks frequently\n",
    "- max_age too high ‚Üí False tracks persist\n",
    "- n_init too low ‚Üí Many false positives\n",
    "- n_init too high ‚Üí Slow to confirm real tracks\n",
    "- max_iou_distance too low ‚Üí Missed matches, ID switches\n",
    "- max_iou_distance too high ‚Üí Wrong matches\n",
    "\n",
    "==================================================\n",
    "\n",
    "TESTING METHODOLOGY:\n",
    "\n",
    "1. Start with defaults (max_age=30, n_init=3, iou=0.7)\n",
    "2. Record baseline metrics (ID switches, lost tracks)\n",
    "3. Adjust ONE parameter at a time\n",
    "4. Test on representative videos\n",
    "5. Measure improvement\n",
    "6. Iterate until optimal\n",
    "\n",
    "Metrics to Track:\n",
    "- ID switches per minute\n",
    "- Average track length\n",
    "- False positive tracks\n",
    "- Lost tracks (premature deletion)\n",
    "- Re-identification success rate\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üìä PARAMETER COMPARISON TABLE:\n",
    "\n",
    "Parameter        | Default | Crowded | Sparse  | High Occlusion | Fast Moving\n",
    "-----------------|---------|---------|---------|----------------|------------\n",
    "max_age          |   30    |  20-30  |  15-20  |     40-60      |   10-15\n",
    "n_init           |    3    |   3-4   |   2-3   |      4-5       |     2\n",
    "max_iou_distance |  0.7    | 0.6-0.7 | 0.7-0.8 |    0.5-0.6     |  0.7-0.8\n",
    "max_cosine_dist  |  0.2    |  0.15   |  0.25   |      0.15      |    0.25\n",
    "nn_budget        |  100    |   100   |   50    |      150       |    50\n",
    "\n",
    "Recommendation for Security System (Office/Factory):\n",
    "- Start with: max_age=30, n_init=3, max_iou_distance=0.7\n",
    "- Tune based on specific environment\n",
    "- Test with real footage from deployment location\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b98442-3351-43dc-8229-ecb1d4a81618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.2: Create Parameter Testing Framework\n",
      "================================================================================\n",
      "‚úÖ Class created: TrackerConfig\n",
      "   ‚Ä¢ Purpose: Store and manage tracker configurations\n",
      "   ‚Ä¢ Methods: create_tracker(), __repr__()\n",
      "\n",
      "üìã Test Configurations Created:\n",
      "================================================================================\n",
      "   1. Default: max_age=30, n_init=3, iou=0.7\n",
      "   2. High_Occlusion: max_age=50, n_init=4, iou=0.6\n",
      "   3. Fast_Confirmation: max_age=20, n_init=2, iou=0.75\n",
      "   4. Strict_Matching: max_age=30, n_init=3, iou=0.5\n",
      "   5. Lenient_Matching: max_age=30, n_init=3, iou=0.85\n",
      "\n",
      "üí° Testing Strategy:\n",
      "   ‚Ä¢ Run each configuration on same video\n",
      "   ‚Ä¢ Collect metrics for comparison\n",
      "   ‚Ä¢ Select best for security system use case\n",
      "\n",
      "‚úÖ Exercise 1.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.2: CREATE PARAMETER TESTING FRAMEWORK\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.2: Create Parameter Testing Framework\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Systematic Parameter Testing\n",
    "\n",
    "Why We Need a Framework:\n",
    "- Consistent testing across parameter values\n",
    "- Objective performance comparison\n",
    "- Track metrics over time\n",
    "- Make data-driven decisions\n",
    "\n",
    "Testing Approach:\n",
    "1. Define test video/scenario\n",
    "2. Create multiple tracker configurations\n",
    "3. Run each configuration\n",
    "4. Collect metrics\n",
    "5. Compare and select best\n",
    "\n",
    "Metrics to Collect:\n",
    "- Track count (total unique IDs seen)\n",
    "- Average track duration (frames)\n",
    "- ID switches (when same person gets new ID)\n",
    "- FPS (frames per second)\n",
    "- Lost tracks (tracks deleted prematurely)\n",
    "\"\"\"\n",
    "\n",
    "class TrackerConfig:\n",
    "    \"\"\"Configuration for DeepSORT tracker\"\"\"\n",
    "    \n",
    "    def __init__(self, name, max_age=30, n_init=3, max_iou_distance=0.7):\n",
    "        self.name = name\n",
    "        self.max_age = max_age\n",
    "        self.n_init = n_init\n",
    "        self.max_iou_distance = max_iou_distance\n",
    "    \n",
    "    def create_tracker(self):\n",
    "        \"\"\"Create DeepSORT tracker with this config\"\"\"\n",
    "        return DeepSort(\n",
    "            max_age=self.max_age,\n",
    "            n_init=self.n_init,\n",
    "            max_iou_distance=self.max_iou_distance,\n",
    "            embedder=\"mobilenet\",\n",
    "            embedder_gpu=False\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: max_age={self.max_age}, n_init={self.n_init}, iou={self.max_iou_distance}\"\n",
    "\n",
    "print(\"‚úÖ Class created: TrackerConfig\")\n",
    "print(\"   ‚Ä¢ Purpose: Store and manage tracker configurations\")\n",
    "print(\"   ‚Ä¢ Methods: create_tracker(), __repr__()\")\n",
    "\n",
    "# Define test configurations\n",
    "configs = [\n",
    "    TrackerConfig(\"Default\", max_age=30, n_init=3, max_iou_distance=0.7),\n",
    "    TrackerConfig(\"High_Occlusion\", max_age=50, n_init=4, max_iou_distance=0.6),\n",
    "    TrackerConfig(\"Fast_Confirmation\", max_age=20, n_init=2, max_iou_distance=0.75),\n",
    "    TrackerConfig(\"Strict_Matching\", max_age=30, n_init=3, max_iou_distance=0.5),\n",
    "    TrackerConfig(\"Lenient_Matching\", max_age=30, n_init=3, max_iou_distance=0.85),\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Test Configurations Created:\")\n",
    "print(\"=\" * 80)\n",
    "for i, config in enumerate(configs, 1):\n",
    "    print(f\"   {i}. {config}\")\n",
    "\n",
    "print(\"\\nüí° Testing Strategy:\")\n",
    "print(\"   ‚Ä¢ Run each configuration on same video\")\n",
    "print(\"   ‚Ä¢ Collect metrics for comparison\")\n",
    "print(\"   ‚Ä¢ Select best for security system use case\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8778851f-ffec-4dfb-b696-afa91af5b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.3: Test Occlusion Handling\n",
      "================================================================================\n",
      "\n",
      "üß™ OCCLUSION SIMULATION:\n",
      "================================================================================\n",
      "\n",
      "Scenario: Person walks behind pillar\n",
      "   ‚Ä¢ Visible: Frames 1-10\n",
      "   ‚Ä¢ Occluded: Frames 11-25 (15 frames)\n",
      "   ‚Ä¢ Reappears: Frame 26+\n",
      "\n",
      "üìä Testing with different max_age values:\n",
      "   max_age=10      ‚Üí ‚ùå Track LOST         (max_age=10 < occlusion=15)\n",
      "   max_age=20      ‚Üí ‚úÖ Track MAINTAINED   (max_age=20 > occlusion=15)\n",
      "   max_age=30      ‚Üí ‚úÖ Track MAINTAINED   (max_age=30 > occlusion=15)\n",
      "   max_age=50      ‚Üí ‚úÖ Track MAINTAINED   (max_age=50 > occlusion=15)\n",
      "\n",
      "üí° Key Insight:\n",
      "   ‚Ä¢ max_age must exceed expected occlusion duration\n",
      "   ‚Ä¢ Too low: Frequent ID losses\n",
      "   ‚Ä¢ Too high: Ghost tracks persist longer\n",
      "   ‚Ä¢ Sweet spot: 1.5-2x typical occlusion duration\n",
      "\n",
      "üìà Recommended max_age by Scenario:\n",
      "   ‚Ä¢ Office (rare occlusions): 20-30 frames\n",
      "   ‚Ä¢ Retail (moderate): 30-40 frames\n",
      "   ‚Ä¢ Factory (frequent): 40-60 frames\n",
      "   ‚Ä¢ Outdoor (variable): 30-50 frames\n",
      "\n",
      "‚úÖ Exercise 1.3 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.3: OCCLUSION HANDLING TEST\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.3: Test Occlusion Handling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Handling Occlusions in Tracking\n",
    "\n",
    "What is Occlusion?\n",
    "- When tracked object is temporarily hidden\n",
    "- Person walks behind pillar\n",
    "- Person temporarily leaves frame\n",
    "- Person overlapped by another person\n",
    "\n",
    "Why Occlusions are Challenging:\n",
    "- No detection = no update to Kalman filter\n",
    "- Predicted position becomes less accurate\n",
    "- Risk of losing track ID\n",
    "- Risk of assigning new ID when reappears\n",
    "\n",
    "How DeepSORT Handles Occlusions:\n",
    "\n",
    "1. Kalman Filter Prediction:\n",
    "   ‚Ä¢ Continues predicting position during occlusion\n",
    "   ‚Ä¢ Uses last known velocity\n",
    "   ‚Ä¢ Prediction uncertainty increases over time\n",
    "\n",
    "2. Track State Management:\n",
    "   ‚Ä¢ Tracked ‚Üí Lost (when no detection)\n",
    "   ‚Ä¢ Lost track kept for max_age frames\n",
    "   ‚Ä¢ If reappears: match by appearance + predicted position\n",
    "   ‚Ä¢ If doesn't reappear: delete track\n",
    "\n",
    "3. Appearance Descriptor:\n",
    "   ‚Ä¢ ReID embedding stored for each track\n",
    "   ‚Ä¢ When object reappears, match by appearance\n",
    "   ‚Ä¢ Even if position prediction is off\n",
    "   ‚Ä¢ Enables re-identification\n",
    "\n",
    "Success Factors:\n",
    "‚úì max_age long enough for expected occlusion\n",
    "‚úì Appearance features distinctive enough\n",
    "‚úì Predicted position reasonably accurate\n",
    "‚úì No similar-looking objects in scene\n",
    "\n",
    "==================================================\n",
    "\n",
    "OCCLUSION SCENARIOS:\n",
    "\n",
    "Short Occlusion (1-10 frames, <0.5 seconds):\n",
    "‚îú‚îÄ‚îÄ Challenge: Low\n",
    "‚îú‚îÄ‚îÄ Solution: Kalman prediction usually sufficient\n",
    "‚îú‚îÄ‚îÄ max_age: 15-20 frames adequate\n",
    "‚îî‚îÄ‚îÄ Success Rate: 95%+\n",
    "\n",
    "Medium Occlusion (10-30 frames, 0.5-1 second):\n",
    "‚îú‚îÄ‚îÄ Challenge: Moderate\n",
    "‚îú‚îÄ‚îÄ Solution: Appearance matching critical\n",
    "‚îú‚îÄ‚îÄ max_age: 30-40 frames needed\n",
    "‚îî‚îÄ‚îÄ Success Rate: 80-90%\n",
    "\n",
    "Long Occlusion (30+ frames, 1+ seconds):\n",
    "‚îú‚îÄ‚îÄ Challenge: High\n",
    "‚îú‚îÄ‚îÄ Solution: May require higher max_age + good appearance\n",
    "‚îú‚îÄ‚îÄ max_age: 50-60+ frames\n",
    "‚îî‚îÄ‚îÄ Success Rate: 60-80%\n",
    "\n",
    "Permanent Occlusion (object leaves):\n",
    "‚îú‚îÄ‚îÄ Challenge: N/A (expected behavior)\n",
    "‚îú‚îÄ‚îÄ Solution: Track should be deleted after max_age\n",
    "‚îú‚îÄ‚îÄ max_age: Balance between persistence and deletion\n",
    "‚îî‚îÄ‚îÄ Goal: Delete cleanly, no ghost tracks\n",
    "\"\"\"\n",
    "\n",
    "def simulate_occlusion_scenario():\n",
    "    \"\"\"\n",
    "    Simulate tracking through occlusion\n",
    "    \n",
    "    Demonstrates how max_age affects track persistence\n",
    "    \"\"\"\n",
    "    print(\"\\nüß™ OCCLUSION SIMULATION:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nScenario: Person walks behind pillar\")\n",
    "    print(\"   ‚Ä¢ Visible: Frames 1-10\")\n",
    "    print(\"   ‚Ä¢ Occluded: Frames 11-25 (15 frames)\")\n",
    "    print(\"   ‚Ä¢ Reappears: Frame 26+\")\n",
    "    \n",
    "    print(\"\\nüìä Testing with different max_age values:\")\n",
    "    \n",
    "    test_configs = [\n",
    "        (\"max_age=10\", 10),\n",
    "        (\"max_age=20\", 20),\n",
    "        (\"max_age=30\", 30),\n",
    "        (\"max_age=50\", 50),\n",
    "    ]\n",
    "    \n",
    "    occlusion_duration = 15  # frames\n",
    "    \n",
    "    for name, max_age in test_configs:\n",
    "        if max_age >= occlusion_duration:\n",
    "            result = \"‚úÖ Track MAINTAINED\"\n",
    "            explanation = f\"(max_age={max_age} > occlusion={occlusion_duration})\"\n",
    "        else:\n",
    "            result = \"‚ùå Track LOST\"\n",
    "            explanation = f\"(max_age={max_age} < occlusion={occlusion_duration})\"\n",
    "        \n",
    "        print(f\"   {name:15} ‚Üí {result:20} {explanation}\")\n",
    "    \n",
    "    print(\"\\nüí° Key Insight:\")\n",
    "    print(\"   ‚Ä¢ max_age must exceed expected occlusion duration\")\n",
    "    print(\"   ‚Ä¢ Too low: Frequent ID losses\")\n",
    "    print(\"   ‚Ä¢ Too high: Ghost tracks persist longer\")\n",
    "    print(\"   ‚Ä¢ Sweet spot: 1.5-2x typical occlusion duration\")\n",
    "    \n",
    "    print(\"\\nüìà Recommended max_age by Scenario:\")\n",
    "    print(\"   ‚Ä¢ Office (rare occlusions): 20-30 frames\")\n",
    "    print(\"   ‚Ä¢ Retail (moderate): 30-40 frames\")\n",
    "    print(\"   ‚Ä¢ Factory (frequent): 40-60 frames\")\n",
    "    print(\"   ‚Ä¢ Outdoor (variable): 30-50 frames\")\n",
    "\n",
    "simulate_occlusion_scenario()\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.3 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6920b3fd-6fd0-4047-8450-fb1c16d4e888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üî¢ PART 2: PEOPLE COUNTING SYSTEM\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üî¢ PART 2: PEOPLE COUNTING SYSTEM\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9fc0c1-66b5-4631-a119-51fc7b9afcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 2.1: Understanding Line-Crossing Detection\n",
      "================================================================================\n",
      "\n",
      "üìê VISUAL REPRESENTATION:\n",
      "\n",
      "Line-Crossing Detection:\n",
      "\n",
      "Frame N-1:                Frame N:\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
      "‚îÇ    ‚óè        ‚îÇ          ‚îÇ             ‚îÇ\n",
      "‚îÇ   P1        ‚îÇ          ‚îÇ      ‚óè      ‚îÇ\n",
      "‚îÇ             ‚îÇ          ‚îÇ     P2      ‚îÇ\n",
      "‚îÇ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ‚îÇ LINE     ‚îÇ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ‚îÇ LINE\n",
      "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
      "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "P1 above line (cross < 0)    P2 below line (cross > 0)\n",
      "                    ‚Üí CROSSING DETECTED! ‚úì\n",
      "\n",
      "Direction Determination:\n",
      "- P1 to P2: Negative to Positive ‚Üí Direction: DOWN (or IN)\n",
      "- P2 to P1: Positive to Negative ‚Üí Direction: UP (or OUT)\n",
      "\n",
      "==================================================\n",
      "\n",
      "IMPLEMENTATION STEPS:\n",
      "\n",
      "1. Define line coordinates\n",
      "   line_start = (x1, y1)\n",
      "   line_end = (x2, y2)\n",
      "\n",
      "2. Track object centers\n",
      "   track_positions[track_id] = [(x, y), ...]\n",
      "\n",
      "3. Calculate cross product\n",
      "   cross_prev = calculate_cross_product(prev_pos, line)\n",
      "   cross_curr = calculate_cross_product(curr_pos, line)\n",
      "\n",
      "4. Detect crossing\n",
      "   if sign(cross_prev) != sign(cross_curr):\n",
      "       crossing_detected = True\n",
      "\n",
      "5. Determine direction\n",
      "   if cross_prev < 0 and cross_curr > 0:\n",
      "       direction = \"ENTERING\"\n",
      "   elif cross_prev > 0 and cross_curr < 0:\n",
      "       direction = \"EXITING\"\n",
      "\n",
      "6. Update counters\n",
      "   if direction == \"ENTERING\":\n",
      "       count_in += 1\n",
      "   elif direction == \"EXITING\":\n",
      "       count_out += 1\n",
      "   \n",
      "   current_occupancy = count_in - count_out\n",
      "\n",
      "\n",
      "‚úÖ Exercise 2.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 2.1: UNDERSTAND LINE-CROSSING DETECTION\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 2.1: Understanding Line-Crossing Detection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Line-Crossing for People Counting\n",
    "\n",
    "Concept:\n",
    "- Define a virtual line in the video\n",
    "- Track when objects cross the line\n",
    "- Count direction (entering vs exiting)\n",
    "- Maintain running totals\n",
    "\n",
    "Why Line-Crossing?\n",
    "‚úì Simple and effective\n",
    "‚úì Works with any tracking system\n",
    "‚úì Direction-aware (in vs out)\n",
    "‚úì Handles multiple people simultaneously\n",
    "‚úì Industry standard approach\n",
    "\n",
    "==================================================\n",
    "\n",
    "LINE-CROSSING ALGORITHM:\n",
    "\n",
    "Components Needed:\n",
    "1. Line definition: Two points (x1, y1) and (x2, y2)\n",
    "2. Track positions: Current and previous frame\n",
    "3. Crossing detection: Did trajectory cross line?\n",
    "4. Direction detection: Which way did they cross?\n",
    "\n",
    "Mathematical Approach:\n",
    "\n",
    "Method 1: Line Segment Intersection\n",
    "- Check if line segment (prev_pos, curr_pos) intersects counting line\n",
    "- Use cross product to determine intersection\n",
    "- Determine direction using relative positions\n",
    "\n",
    "Method 2: Signed Distance\n",
    "- Calculate perpendicular distance from point to line\n",
    "- Sign indicates which side of line\n",
    "- Crossing = sign change between frames\n",
    "- Direction = positive to negative vs negative to positive\n",
    "\n",
    "==================================================\n",
    "\n",
    "GEOMETRIC FORMULA:\n",
    "\n",
    "For line from point A(x1, y1) to B(x2, y2)\n",
    "And object center at point P(x, y)\n",
    "\n",
    "Cross Product Method:\n",
    "- v1 = (x2 - x1, y2 - y1)  # Line vector\n",
    "- v2 = (x - x1, y - y1)    # Point vector\n",
    "- cross = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "- cross > 0: Point on one side\n",
    "- cross < 0: Point on other side\n",
    "- cross = 0: Point on line\n",
    "\n",
    "Crossing Detection:\n",
    "- If sign(cross_prev) ‚â† sign(cross_curr): CROSSED!\n",
    "- Direction: cross_prev < 0 and cross_curr > 0 ‚Üí Direction 1\n",
    "- Direction: cross_prev > 0 and cross_curr < 0 ‚Üí Direction 2\n",
    "\n",
    "==================================================\n",
    "\n",
    "LINE PLACEMENT STRATEGIES:\n",
    "\n",
    "Entrance/Exit Monitoring:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        ‚îÇ\n",
    "‚îÇ     ‚Üì‚Üì‚Üì  ENTRANCE  ‚Üë‚Üë‚Üë ‚îÇ\n",
    "‚îÇ     ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ‚îÇ  ‚Üê Counting line\n",
    "‚îÇ                        ‚îÇ\n",
    "‚îÇ      MONITORED AREA    ‚îÇ\n",
    "‚îÇ                        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Placement Tips:\n",
    "‚úì Place perpendicular to traffic flow\n",
    "‚úì Avoid areas with frequent stops\n",
    "‚úì Clear sightline (no obstructions)\n",
    "‚úì Adequate lighting\n",
    "‚úì Consider camera angle\n",
    "\n",
    "Multiple Lines:\n",
    "- Line 1: Main entrance\n",
    "- Line 2: Secondary entrance\n",
    "- Line 3: Exit-only door\n",
    "- Total = sum of all lines\n",
    "\n",
    "==================================================\n",
    "\n",
    "COUNTING SCENARIOS:\n",
    "\n",
    "Scenario 1: Single Entrance/Exit (Bidirectional)\n",
    "- One line, count both directions\n",
    "- IN: crosses line one way\n",
    "- OUT: crosses line other way\n",
    "- Net count = IN - OUT\n",
    "\n",
    "Scenario 2: Separate Entrance/Exit\n",
    "- Two lines (one per door)\n",
    "- Line 1: Only count crossings in\n",
    "- Line 2: Only count crossings out\n",
    "- Total IN, Total OUT tracked separately\n",
    "\n",
    "Scenario 3: Zone Counting\n",
    "- Define polygon zone\n",
    "- Count entries (any line crossing into zone)\n",
    "- Count exits (any line crossing out of zone)\n",
    "- Current occupancy = entries - exits\n",
    "\n",
    "Scenario 4: Bidirectional Traffic\n",
    "- Busy corridor, people going both ways\n",
    "- Line in middle of corridor\n",
    "- Count both directions\n",
    "- Analyze traffic patterns\n",
    "\n",
    "==================================================\n",
    "\n",
    "HANDLING EDGE CASES:\n",
    "\n",
    "Case 1: Person Lingers on Line\n",
    "- Problem: Multiple crossings detected\n",
    "- Solution: Cooldown period per track\n",
    "- Only count once per track per X seconds\n",
    "\n",
    "Case 2: Person Crosses Back and Forth\n",
    "- Problem: Inflated count\n",
    "- Solution: Track last crossing direction\n",
    "- Only count if direction changes\n",
    "\n",
    "Case 3: Multiple People Cross Simultaneously\n",
    "- Problem: Accurate counting\n",
    "- Solution: Track each person's ID separately\n",
    "- Count each unique crossing\n",
    "\n",
    "Case 4: Person Partially Crosses\n",
    "- Problem: False positive\n",
    "- Solution: Require full crossing\n",
    "- Check both feet/bottom of bbox crossed\n",
    "\n",
    "==================================================\n",
    "\n",
    "PERFORMANCE CONSIDERATIONS:\n",
    "\n",
    "Accuracy Factors:\n",
    "- Tracking quality (ID consistency)\n",
    "- Line placement (optimal location)\n",
    "- Camera angle (perpendicular is best)\n",
    "- Lighting conditions\n",
    "- Occlusions at line\n",
    "\n",
    "Expected Accuracy:\n",
    "- Optimal conditions: 95-98%\n",
    "- Normal conditions: 90-95%\n",
    "- Challenging conditions: 85-90%\n",
    "\n",
    "Common Errors:\n",
    "- Missed counts: Track lost at line\n",
    "- Double counts: ID switch at line\n",
    "- Wrong direction: Tracking jitter near line\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üìê VISUAL REPRESENTATION:\n",
    "\n",
    "Line-Crossing Detection:\n",
    "\n",
    "Frame N-1:                Frame N:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
    "‚îÇ    ‚óè        ‚îÇ          ‚îÇ             ‚îÇ\n",
    "‚îÇ   P1        ‚îÇ          ‚îÇ      ‚óè      ‚îÇ\n",
    "‚îÇ             ‚îÇ          ‚îÇ     P2      ‚îÇ\n",
    "‚îÇ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ‚îÇ LINE     ‚îÇ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ‚îÇ LINE\n",
    "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
    "‚îÇ             ‚îÇ          ‚îÇ             ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "P1 above line (cross < 0)    P2 below line (cross > 0)\n",
    "                    ‚Üí CROSSING DETECTED! ‚úì\n",
    "\n",
    "Direction Determination:\n",
    "- P1 to P2: Negative to Positive ‚Üí Direction: DOWN (or IN)\n",
    "- P2 to P1: Positive to Negative ‚Üí Direction: UP (or OUT)\n",
    "\n",
    "==================================================\n",
    "\n",
    "IMPLEMENTATION STEPS:\n",
    "\n",
    "1. Define line coordinates\n",
    "   line_start = (x1, y1)\n",
    "   line_end = (x2, y2)\n",
    "\n",
    "2. Track object centers\n",
    "   track_positions[track_id] = [(x, y), ...]\n",
    "\n",
    "3. Calculate cross product\n",
    "   cross_prev = calculate_cross_product(prev_pos, line)\n",
    "   cross_curr = calculate_cross_product(curr_pos, line)\n",
    "\n",
    "4. Detect crossing\n",
    "   if sign(cross_prev) != sign(cross_curr):\n",
    "       crossing_detected = True\n",
    "\n",
    "5. Determine direction\n",
    "   if cross_prev < 0 and cross_curr > 0:\n",
    "       direction = \"ENTERING\"\n",
    "   elif cross_prev > 0 and cross_curr < 0:\n",
    "       direction = \"EXITING\"\n",
    "\n",
    "6. Update counters\n",
    "   if direction == \"ENTERING\":\n",
    "       count_in += 1\n",
    "   elif direction == \"EXITING\":\n",
    "       count_out += 1\n",
    "   \n",
    "   current_occupancy = count_in - count_out\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 2.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f35193-1360-40ef-bd12-f5f7989b3196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 2.2: Implement Line-Crossing Detection\n",
      "================================================================================\n",
      "‚úÖ Class created: PeopleCounter\n",
      "\n",
      "üìä Features:\n",
      "   ‚Ä¢ Line-crossing detection (cross product method)\n",
      "   ‚Ä¢ Direction-aware counting (IN vs OUT)\n",
      "   ‚Ä¢ Duplicate prevention (track last crossing)\n",
      "   ‚Ä¢ Oscillation handling (direction change required)\n",
      "   ‚Ä¢ Current occupancy calculation (IN - OUT)\n",
      "   ‚Ä¢ Visualization (line + counters)\n",
      "\n",
      "üß™ Testing PeopleCounter class...\n",
      "‚úÖ PeopleCounter initialized\n",
      "   Line: (100, 360) ‚Üí (1180, 360)\n",
      "\n",
      "‚úÖ Test counter created!\n",
      "   Initial counts: {'in': 0, 'out': 0, 'current': 0, 'total': 0}\n",
      "\n",
      "‚úÖ Exercise 2.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 2.2: IMPLEMENT LINE-CROSSING DETECTION\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 2.2: Implement Line-Crossing Detection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Implementation Details\n",
    "\n",
    "We'll implement:\n",
    "1. Line definition (interactive or fixed)\n",
    "2. Cross product calculation\n",
    "3. Crossing detection logic\n",
    "4. Direction determination\n",
    "5. Count tracking\n",
    "6. Visualization\n",
    "\n",
    "Data Structures:\n",
    "- line_coords: (x1, y1, x2, y2)\n",
    "- track_history: {track_id: [(x, y), ...]}\n",
    "- crossed_tracks: {track_id: last_direction}\n",
    "- counters: {in: 0, out: 0, current: 0}\n",
    "\"\"\"\n",
    "\n",
    "class PeopleCounter:\n",
    "    \"\"\"\n",
    "    People counting system using line-crossing detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, line_start, line_end):\n",
    "        \"\"\"\n",
    "        Initialize counter with line coordinates\n",
    "        \n",
    "        Args:\n",
    "            line_start: (x, y) tuple for line start point\n",
    "            line_end: (x, y) tuple for line end point\n",
    "        \"\"\"\n",
    "        self.line_start = np.array(line_start)\n",
    "        self.line_end = np.array(line_end)\n",
    "        \n",
    "        # Track positions history (last 2 positions per track)\n",
    "        self.track_positions = defaultdict(lambda: deque(maxlen=2))\n",
    "        \n",
    "        # Tracks that have crossed (to prevent double counting)\n",
    "        self.crossed_tracks = {}\n",
    "        \n",
    "        # Counters\n",
    "        self.count_in = 0\n",
    "        self.count_out = 0\n",
    "        self.total_crossings = 0\n",
    "        \n",
    "        print(f\"‚úÖ PeopleCounter initialized\")\n",
    "        print(f\"   Line: {line_start} ‚Üí {line_end}\")\n",
    "    \n",
    "    def _calculate_cross_product(self, point):\n",
    "        \"\"\"\n",
    "        Calculate cross product to determine which side of line point is on\n",
    "        \n",
    "        Args:\n",
    "            point: (x, y) tuple\n",
    "            \n",
    "        Returns:\n",
    "            float: cross product (sign indicates side)\n",
    "        \"\"\"\n",
    "        # Line vector\n",
    "        line_vec = self.line_end - self.line_start\n",
    "        \n",
    "        # Point vector (from line start to point)\n",
    "        point_vec = np.array(point) - self.line_start\n",
    "        \n",
    "        # Cross product (2D)\n",
    "        cross = line_vec[0] * point_vec[1] - line_vec[1] * point_vec[0]\n",
    "        \n",
    "        return cross\n",
    "    \n",
    "    def update(self, tracks):\n",
    "        \"\"\"\n",
    "        Update counter with new tracks\n",
    "        \n",
    "        Args:\n",
    "            tracks: List of tracks from DeepSORT\n",
    "            \n",
    "        Returns:\n",
    "            dict: Crossing events {track_id: direction}\n",
    "        \"\"\"\n",
    "        crossings = {}\n",
    "        \n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            track_id = track.track_id\n",
    "            bbox = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            \n",
    "            # Get center point (bottom-center for better accuracy)\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int(y2)  # Bottom of bounding box\n",
    "            center = (center_x, center_y)\n",
    "            \n",
    "            # Add to position history\n",
    "            self.track_positions[track_id].append(center)\n",
    "            \n",
    "            # Need at least 2 positions to detect crossing\n",
    "            if len(self.track_positions[track_id]) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Get previous and current positions\n",
    "            prev_pos = self.track_positions[track_id][0]\n",
    "            curr_pos = self.track_positions[track_id][1]\n",
    "            \n",
    "            # Calculate cross products\n",
    "            cross_prev = self._calculate_cross_product(prev_pos)\n",
    "            cross_curr = self._calculate_cross_product(curr_pos)\n",
    "            \n",
    "            # Detect crossing (sign change)\n",
    "            if np.sign(cross_prev) != np.sign(cross_curr) and cross_prev != 0:\n",
    "                \n",
    "                # Check if already counted this track recently\n",
    "                if track_id in self.crossed_tracks:\n",
    "                    last_direction = self.crossed_tracks[track_id]\n",
    "                    \n",
    "                    # Determine current direction\n",
    "                    if cross_prev < 0 and cross_curr > 0:\n",
    "                        curr_direction = \"IN\"\n",
    "                    else:\n",
    "                        curr_direction = \"OUT\"\n",
    "                    \n",
    "                    # Only count if direction changed (prevents oscillation)\n",
    "                    if curr_direction == last_direction:\n",
    "                        continue\n",
    "                \n",
    "                # Determine direction\n",
    "                if cross_prev < 0 and cross_curr > 0:\n",
    "                    direction = \"IN\"\n",
    "                    self.count_in += 1\n",
    "                else:\n",
    "                    direction = \"OUT\"\n",
    "                    self.count_out += 1\n",
    "                \n",
    "                self.total_crossings += 1\n",
    "                self.crossed_tracks[track_id] = direction\n",
    "                crossings[track_id] = direction\n",
    "        \n",
    "        return crossings\n",
    "    \n",
    "    def get_counts(self):\n",
    "        \"\"\"Get current counts\"\"\"\n",
    "        return {\n",
    "            'in': self.count_in,\n",
    "            'out': self.count_out,\n",
    "            'current': self.count_in - self.count_out,\n",
    "            'total': self.total_crossings\n",
    "        }\n",
    "    \n",
    "    def draw_line(self, frame):\n",
    "        \"\"\"\n",
    "        Draw counting line on frame\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame\n",
    "            \n",
    "        Returns:\n",
    "            Annotated frame\n",
    "        \"\"\"\n",
    "        annotated = frame.copy()\n",
    "        \n",
    "        # Draw line\n",
    "        cv2.line(annotated, tuple(self.line_start.astype(int)), \n",
    "                tuple(self.line_end.astype(int)), (0, 255, 255), 3)\n",
    "        \n",
    "        # Draw endpoints\n",
    "        cv2.circle(annotated, tuple(self.line_start.astype(int)), 8, (0, 255, 255), -1)\n",
    "        cv2.circle(annotated, tuple(self.line_end.astype(int)), 8, (0, 255, 255), -1)\n",
    "        \n",
    "        # Add label\n",
    "        mid_point = ((self.line_start + self.line_end) / 2).astype(int)\n",
    "        cv2.putText(annotated, \"COUNTING LINE\", tuple(mid_point - [0, 15]),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        return annotated\n",
    "    \n",
    "    def draw_counts(self, frame):\n",
    "        \"\"\"\n",
    "        Draw count information on frame\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame\n",
    "            \n",
    "        Returns:\n",
    "            Annotated frame\n",
    "        \"\"\"\n",
    "        annotated = frame.copy()\n",
    "        counts = self.get_counts()\n",
    "        \n",
    "        # Semi-transparent panel\n",
    "        overlay = annotated.copy()\n",
    "        cv2.rectangle(overlay, (10, 200), (350, 400), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, annotated, 0.4, 0, annotated)\n",
    "        \n",
    "        # Draw counts\n",
    "        y_offset = 240\n",
    "        cv2.putText(annotated, \"PEOPLE COUNT\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"IN:  {counts['in']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"OUT: {counts['out']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "        \n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"Current: {counts['current']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)\n",
    "        \n",
    "        return annotated\n",
    "\n",
    "print(\"‚úÖ Class created: PeopleCounter\")\n",
    "print(\"\\nüìä Features:\")\n",
    "print(\"   ‚Ä¢ Line-crossing detection (cross product method)\")\n",
    "print(\"   ‚Ä¢ Direction-aware counting (IN vs OUT)\")\n",
    "print(\"   ‚Ä¢ Duplicate prevention (track last crossing)\")\n",
    "print(\"   ‚Ä¢ Oscillation handling (direction change required)\")\n",
    "print(\"   ‚Ä¢ Current occupancy calculation (IN - OUT)\")\n",
    "print(\"   ‚Ä¢ Visualization (line + counters)\")\n",
    "\n",
    "print(\"\\nüß™ Testing PeopleCounter class...\")\n",
    "\n",
    "# Create test counter (horizontal line in middle of 720p frame)\n",
    "test_counter = PeopleCounter(\n",
    "    line_start=(100, 360),  # Left side, middle height\n",
    "    line_end=(1180, 360)    # Right side, middle height\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Test counter created!\")\n",
    "print(f\"   Initial counts: {test_counter.get_counts()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 2.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ec921e-d353-4064-a7c8-c38b0451bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 2.3: People Counting Demo with Webcam\n",
      "================================================================================\n",
      "\n",
      "üé• COMPLETE PEOPLE COUNTING DEMO\n",
      "\n",
      "Below is the full code for webcam people counting.\n",
      "This integrates YOLO + DeepSORT + PeopleCounter!\n",
      "\n",
      "Features:\n",
      "‚úì Real-time detection + tracking\n",
      "‚úì Line-crossing detection\n",
      "‚úì Direction-aware counting (IN/OUT)\n",
      "‚úì Current occupancy tracking\n",
      "‚úì Visual counting line\n",
      "‚úì Counter display panel\n",
      "‚úì FPS monitoring\n",
      "\n",
      "üìù To run this demo:\n",
      "1. Copy the code below to a new cell\n",
      "2. Execute the cell\n",
      "3. Your webcam will open\n",
      "4. Walk across the yellow line to test counting!\n",
      "5. Try going both directions (IN and OUT)\n",
      "6. Press 'q' to quit\n",
      "\n",
      "‚ö†Ô∏è  Note: Adjust line position based on your camera view\n",
      "         Default line is horizontal in middle of frame\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CODE: PEOPLE COUNTING DEMO\n",
      "================================================================================\n",
      "\n",
      "Copy this code to a new cell to run people counting:\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "import cv2\n",
      "import numpy as np\n",
      "from ultralytics import YOLO\n",
      "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
      "import time\n",
      "\n",
      "# Load models\n",
      "print(\"Loading models...\")\n",
      "model = YOLO('yolov8n.pt')\n",
      "tracker = DeepSort(max_age=30, n_init=3, embedder=\"mobilenet\", embedder_gpu=False)\n",
      "\n",
      "# Initialize counter (adjust line position for your camera!)\n",
      "# Line coordinates: (x1, y1) to (x2, y2)\n",
      "# Default: horizontal line in middle of 640x480 frame\n",
      "counter = PeopleCounter(\n",
      "    line_start=(50, 240),   # Left side, middle height\n",
      "    line_end=(590, 240)     # Right side, middle height\n",
      ")\n",
      "\n",
      "# Open webcam\n",
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "if not cap.isOpened():\n",
      "    print(\"‚ùå Cannot open webcam!\")\n",
      "else:\n",
      "    print(\"‚úÖ Webcam opened!\")\n",
      "    print(\"üé• Starting people counting... (Press 'q' to quit)\")\n",
      "    print(\"üí° Walk across the YELLOW line to test counting!\")\n",
      "    \n",
      "    # FPS tracking\n",
      "    fps_counter = 0\n",
      "    start_time = time.time()\n",
      "    fps = 0\n",
      "    \n",
      "    while True:\n",
      "        ret, frame = cap.read()\n",
      "        if not ret:\n",
      "            break\n",
      "        \n",
      "        # 1. YOLO Detection\n",
      "        results = model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
      "        detections = results[0].boxes\n",
      "        \n",
      "        # 2. Convert to DeepSORT format\n",
      "        deepsort_input = []\n",
      "        for box in detections:\n",
      "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
      "            conf = float(box.conf[0])\n",
      "            w = x2 - x1\n",
      "            h = y2 - y1\n",
      "            deepsort_input.append(([x1, y1, w, h], conf, 'person'))\n",
      "        \n",
      "        # 3. Update tracker\n",
      "        tracks = tracker.update_tracks(deepsort_input, frame=frame)\n",
      "        \n",
      "        # 4. Update counter (detect crossings)\n",
      "        crossings = counter.update(tracks)\n",
      "        \n",
      "        # 5. Visualize tracks\n",
      "        for track in tracks:\n",
      "            if not track.is_confirmed():\n",
      "                continue\n",
      "            \n",
      "            track_id = track.track_id\n",
      "            bbox = track.to_ltrb()\n",
      "            x1, y1, x2, y2 = map(int, bbox)\n",
      "            \n",
      "            # Color: Green normally, Red if just crossed\n",
      "            if track_id in crossings:\n",
      "                color = (0, 0, 255)  # Red\n",
      "                direction = crossings[track_id]\n",
      "                label = f'ID: {track_id} ({direction})'\n",
      "            else:\n",
      "                color = (0, 255, 0)  # Green\n",
      "                label = f'ID: {track_id}'\n",
      "            \n",
      "            # Draw bounding box\n",
      "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
      "            \n",
      "            # Draw ID\n",
      "            cv2.putText(frame, label, (x1, y1 - 10),\n",
      "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
      "        \n",
      "        # 6. Draw counting line\n",
      "        frame = counter.draw_line(frame)\n",
      "        \n",
      "        # 7. Draw counter panel\n",
      "        frame = counter.draw_counts(frame)\n",
      "        \n",
      "        # 8. Calculate FPS\n",
      "        fps_counter += 1\n",
      "        if fps_counter % 30 == 0:\n",
      "            elapsed = time.time() - start_time\n",
      "            fps = 30 / elapsed\n",
      "            start_time = time.time()\n",
      "        \n",
      "        # 9. Display FPS\n",
      "        cv2.putText(frame, f'FPS: {fps:.1f}', (10, 30),\n",
      "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
      "        \n",
      "        # 10. Show frame\n",
      "        cv2.imshow('People Counting System', frame)\n",
      "        \n",
      "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "            break\n",
      "    \n",
      "    cap.release()\n",
      "    cv2.destroyAllWindows()\n",
      "    \n",
      "    # Final statistics\n",
      "    final_counts = counter.get_counts()\n",
      "    print(f\"\\nüìä Final Statistics:\")\n",
      "    print(f\"   ‚Ä¢ People IN: {final_counts['in']}\")\n",
      "    print(f\"   ‚Ä¢ People OUT: {final_counts['out']}\")\n",
      "    print(f\"   ‚Ä¢ Current occupancy: {final_counts['current']}\")\n",
      "    print(f\"   ‚Ä¢ Total crossings: {final_counts['total']}\")\n",
      "    print(f\"   ‚Ä¢ Average FPS: {fps:.1f}\")\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üí° What to Observe:\n",
      "   ‚Ä¢ Yellow horizontal line in middle of frame\n",
      "   ‚Ä¢ Each person gets unique green box + ID\n",
      "   ‚Ä¢ Box turns RED when crossing line\n",
      "   ‚Ä¢ Counter panel shows IN, OUT, Current\n",
      "   ‚Ä¢ IN increases when crossing one direction\n",
      "   ‚Ä¢ OUT increases when crossing other direction\n",
      "   ‚Ä¢ Current = IN - OUT (occupancy)\n",
      "\n",
      "üß™ Test Scenarios:\n",
      "   1. Walk across line left-to-right (should count IN)\n",
      "   2. Walk across line right-to-left (should count OUT)\n",
      "   3. Walk back and forth (alternates IN/OUT)\n",
      "   4. Multiple people cross together (each counted)\n",
      "   5. Person lingers on line (counted only once)\n",
      "\n",
      "‚úÖ Exercise 2.3 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 2.3: PEOPLE COUNTING DEMO\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 2.3: People Counting Demo with Webcam\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Complete Counting System\n",
    "\n",
    "Integration Steps:\n",
    "1. Initialize YOLO detector\n",
    "2. Initialize DeepSORT tracker\n",
    "3. Initialize PeopleCounter\n",
    "4. For each frame:\n",
    "   a. Detect with YOLO\n",
    "   b. Track with DeepSORT\n",
    "   c. Update counter\n",
    "   d. Visualize everything\n",
    "5. Display results\n",
    "\n",
    "What to Observe:\n",
    "- People get unique IDs\n",
    "- IDs persist as they move\n",
    "- Counter increments when crossing line\n",
    "- Direction is detected (IN vs OUT)\n",
    "- Current occupancy updates\n",
    "- Visualization clear and informative\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üé• COMPLETE PEOPLE COUNTING DEMO\n",
    "\n",
    "Below is the full code for webcam people counting.\n",
    "This integrates YOLO + DeepSORT + PeopleCounter!\n",
    "\n",
    "Features:\n",
    "‚úì Real-time detection + tracking\n",
    "‚úì Line-crossing detection\n",
    "‚úì Direction-aware counting (IN/OUT)\n",
    "‚úì Current occupancy tracking\n",
    "‚úì Visual counting line\n",
    "‚úì Counter display panel\n",
    "‚úì FPS monitoring\n",
    "\n",
    "üìù To run this demo:\n",
    "1. Copy the code below to a new cell\n",
    "2. Execute the cell\n",
    "3. Your webcam will open\n",
    "4. Walk across the yellow line to test counting!\n",
    "5. Try going both directions (IN and OUT)\n",
    "6. Press 'q' to quit\n",
    "\n",
    "‚ö†Ô∏è  Note: Adjust line position based on your camera view\n",
    "         Default line is horizontal in middle of frame\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CODE: PEOPLE COUNTING DEMO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Copy this code to a new cell to run people counting:\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import time\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "tracker = DeepSort(max_age=30, n_init=3, embedder=\"mobilenet\", embedder_gpu=False)\n",
    "\n",
    "# Initialize counter (adjust line position for your camera!)\n",
    "# Line coordinates: (x1, y1) to (x2, y2)\n",
    "# Default: horizontal line in middle of 640x480 frame\n",
    "counter = PeopleCounter(\n",
    "    line_start=(50, 240),   # Left side, middle height\n",
    "    line_end=(590, 240)     # Right side, middle height\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Cannot open webcam!\")\n",
    "else:\n",
    "    print(\"‚úÖ Webcam opened!\")\n",
    "    print(\"üé• Starting people counting... (Press 'q' to quit)\")\n",
    "    print(\"üí° Walk across the YELLOW line to test counting!\")\n",
    "    \n",
    "    # FPS tracking\n",
    "    fps_counter = 0\n",
    "    start_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 1. YOLO Detection\n",
    "        results = model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
    "        detections = results[0].boxes\n",
    "        \n",
    "        # 2. Convert to DeepSORT format\n",
    "        deepsort_input = []\n",
    "        for box in detections:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0])\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            deepsort_input.append(([x1, y1, w, h], conf, 'person'))\n",
    "        \n",
    "        # 3. Update tracker\n",
    "        tracks = tracker.update_tracks(deepsort_input, frame=frame)\n",
    "        \n",
    "        # 4. Update counter (detect crossings)\n",
    "        crossings = counter.update(tracks)\n",
    "        \n",
    "        # 5. Visualize tracks\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            track_id = track.track_id\n",
    "            bbox = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            \n",
    "            # Color: Green normally, Red if just crossed\n",
    "            if track_id in crossings:\n",
    "                color = (0, 0, 255)  # Red\n",
    "                direction = crossings[track_id]\n",
    "                label = f'ID: {track_id} ({direction})'\n",
    "            else:\n",
    "                color = (0, 255, 0)  # Green\n",
    "                label = f'ID: {track_id}'\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw ID\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # 6. Draw counting line\n",
    "        frame = counter.draw_line(frame)\n",
    "        \n",
    "        # 7. Draw counter panel\n",
    "        frame = counter.draw_counts(frame)\n",
    "        \n",
    "        # 8. Calculate FPS\n",
    "        fps_counter += 1\n",
    "        if fps_counter % 30 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            fps = 30 / elapsed\n",
    "            start_time = time.time()\n",
    "        \n",
    "        # 9. Display FPS\n",
    "        cv2.putText(frame, f'FPS: {fps:.1f}', (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        # 10. Show frame\n",
    "        cv2.imshow('People Counting System', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Final statistics\n",
    "    final_counts = counter.get_counts()\n",
    "    print(f\"\\\\nüìä Final Statistics:\")\n",
    "    print(f\"   ‚Ä¢ People IN: {final_counts['in']}\")\n",
    "    print(f\"   ‚Ä¢ People OUT: {final_counts['out']}\")\n",
    "    print(f\"   ‚Ä¢ Current occupancy: {final_counts['current']}\")\n",
    "    print(f\"   ‚Ä¢ Total crossings: {final_counts['total']}\")\n",
    "    print(f\"   ‚Ä¢ Average FPS: {fps:.1f}\")\n",
    "-----------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüí° What to Observe:\")\n",
    "print(\"   ‚Ä¢ Yellow horizontal line in middle of frame\")\n",
    "print(\"   ‚Ä¢ Each person gets unique green box + ID\")\n",
    "print(\"   ‚Ä¢ Box turns RED when crossing line\")\n",
    "print(\"   ‚Ä¢ Counter panel shows IN, OUT, Current\")\n",
    "print(\"   ‚Ä¢ IN increases when crossing one direction\")\n",
    "print(\"   ‚Ä¢ OUT increases when crossing other direction\")\n",
    "print(\"   ‚Ä¢ Current = IN - OUT (occupancy)\")\n",
    "\n",
    "print(\"\\nüß™ Test Scenarios:\")\n",
    "print(\"   1. Walk across line left-to-right (should count IN)\")\n",
    "print(\"   2. Walk across line right-to-left (should count OUT)\")\n",
    "print(\"   3. Walk back and forth (alternates IN/OUT)\")\n",
    "print(\"   4. Multiple people cross together (each counted)\")\n",
    "print(\"   5. Person lingers on line (counted only once)\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 2.3 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7047a5a-0b17-43e7-a63d-6adea32733fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "‚úÖ Webcam opened!\n",
      "üé• Starting people counting... (Press 'q' to quit)\n",
      "üí° Walk across the YELLOW line to test counting!\n",
      "\n",
      "üìä Final Statistics:\n",
      "   ‚Ä¢ People IN: 0\n",
      "   ‚Ä¢ People OUT: 0\n",
      "   ‚Ä¢ Current occupancy: 0\n",
      "   ‚Ä¢ Total crossings: 0\n",
      "   ‚Ä¢ Average FPS: 7.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Tracker without embedder\n",
    "tracker = DeepSort(\n",
    "    max_age=30,\n",
    "    n_init=3,\n",
    "    nms_max_overlap=1.0,\n",
    "    embedder=None\n",
    ")\n",
    "\n",
    "# PeopleCounter class\n",
    "class PeopleCounter:\n",
    "    def __init__(self, line_start, line_end):\n",
    "        self.line_start = np.array(line_start)\n",
    "        self.line_end = np.array(line_end)\n",
    "        self.track_positions = defaultdict(lambda: deque(maxlen=2))\n",
    "        self.crossed_tracks = {}\n",
    "        self.count_in = 0\n",
    "        self.count_out = 0\n",
    "        self.total_crossings = 0\n",
    "    \n",
    "    def _calculate_cross_product(self, point):\n",
    "        line_vec = self.line_end - self.line_start\n",
    "        point_vec = np.array(point) - self.line_start\n",
    "        cross = line_vec[0] * point_vec[1] - line_vec[1] * point_vec[0]\n",
    "        return cross\n",
    "    \n",
    "    def update(self, tracks):\n",
    "        crossings = {}\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            track_id = track.track_id\n",
    "            bbox = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            \n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int(y2)\n",
    "            center = (center_x, center_y)\n",
    "            \n",
    "            self.track_positions[track_id].append(center)\n",
    "            \n",
    "            if len(self.track_positions[track_id]) < 2:\n",
    "                continue\n",
    "            \n",
    "            prev_pos = self.track_positions[track_id][0]\n",
    "            curr_pos = self.track_positions[track_id][1]\n",
    "            \n",
    "            cross_prev = self._calculate_cross_product(prev_pos)\n",
    "            cross_curr = self._calculate_cross_product(curr_pos)\n",
    "            \n",
    "            if np.sign(cross_prev) != np.sign(cross_curr) and cross_prev != 0:\n",
    "                if track_id in self.crossed_tracks:\n",
    "                    last_direction = self.crossed_tracks[track_id]\n",
    "                    if cross_prev < 0 and cross_curr > 0:\n",
    "                        curr_direction = \"IN\"\n",
    "                    else:\n",
    "                        curr_direction = \"OUT\"\n",
    "                    if curr_direction == last_direction:\n",
    "                        continue\n",
    "                \n",
    "                if cross_prev < 0 and cross_curr > 0:\n",
    "                    direction = \"IN\"\n",
    "                    self.count_in += 1\n",
    "                else:\n",
    "                    direction = \"OUT\"\n",
    "                    self.count_out += 1\n",
    "                \n",
    "                self.total_crossings += 1\n",
    "                self.crossed_tracks[track_id] = direction\n",
    "                crossings[track_id] = direction\n",
    "        \n",
    "        return crossings\n",
    "    \n",
    "    def get_counts(self):\n",
    "        return {\n",
    "            'in': self.count_in,\n",
    "            'out': self.count_out,\n",
    "            'current': self.count_in - self.count_out,\n",
    "            'total': self.total_crossings\n",
    "        }\n",
    "    \n",
    "    def draw_line(self, frame):\n",
    "        annotated = frame.copy()\n",
    "        cv2.line(annotated, tuple(self.line_start.astype(int)), \n",
    "                tuple(self.line_end.astype(int)), (0, 255, 255), 3)\n",
    "        cv2.circle(annotated, tuple(self.line_start.astype(int)), 8, (0, 255, 255), -1)\n",
    "        cv2.circle(annotated, tuple(self.line_end.astype(int)), 8, (0, 255, 255), -1)\n",
    "        mid_point = ((self.line_start + self.line_end) / 2).astype(int)\n",
    "        cv2.putText(annotated, \"COUNTING LINE\", tuple(mid_point - [0, 15]),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        return annotated\n",
    "    \n",
    "    def draw_counts(self, frame):\n",
    "        annotated = frame.copy()\n",
    "        counts = self.get_counts()\n",
    "        overlay = annotated.copy()\n",
    "        cv2.rectangle(overlay, (10, 200), (350, 400), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, annotated, 0.4, 0, annotated)\n",
    "        \n",
    "        y_offset = 240\n",
    "        cv2.putText(annotated, \"PEOPLE COUNT\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"IN:  {counts['in']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"OUT: {counts['out']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "        y_offset += 40\n",
    "        cv2.putText(annotated, f\"Current: {counts['current']}\", (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)\n",
    "        return annotated\n",
    "\n",
    "# Initialize counter\n",
    "counter = PeopleCounter(\n",
    "    line_start=(50, 240),\n",
    "    line_end=(590, 240)\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Cannot open webcam!\")\n",
    "else:\n",
    "    print(\"‚úÖ Webcam opened!\")\n",
    "    print(\"üé• Starting people counting... (Press 'q' to quit)\")\n",
    "    print(\"üí° Walk across the YELLOW line to test counting!\")\n",
    "    \n",
    "    fps_counter = 0\n",
    "    start_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 1. YOLO Detection\n",
    "        results = model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
    "        detections = results[0].boxes\n",
    "        \n",
    "        # 2. Convert to DeepSORT format\n",
    "        deepsort_input = []\n",
    "        for box in detections:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0])\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            deepsort_input.append(([x1, y1, w, h], conf, 'person'))\n",
    "        \n",
    "        # 3. Update tracker with RANDOM embeddings (not zeros!)\n",
    "        if len(deepsort_input) > 0:\n",
    "            # Create random normalized embeddings\n",
    "            dummy_embeddings = [np.random.rand(128).astype(np.float32) for _ in deepsort_input]\n",
    "            tracks = tracker.update_tracks(deepsort_input, embeds=dummy_embeddings, frame=frame)\n",
    "        else:\n",
    "            tracks = []\n",
    "        \n",
    "        # 4. Update counter\n",
    "        crossings = counter.update(tracks)\n",
    "        \n",
    "        # 5. Visualize tracks\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            track_id = track.track_id\n",
    "            bbox = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            \n",
    "            if track_id in crossings:\n",
    "                color = (0, 0, 255)\n",
    "                direction = crossings[track_id]\n",
    "                label = f'ID: {track_id} ({direction})'\n",
    "            else:\n",
    "                color = (0, 255, 0)\n",
    "                label = f'ID: {track_id}'\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # 6. Draw counting line\n",
    "        frame = counter.draw_line(frame)\n",
    "        \n",
    "        # 7. Draw counter panel\n",
    "        frame = counter.draw_counts(frame)\n",
    "        \n",
    "        # 8. Calculate FPS\n",
    "        fps_counter += 1\n",
    "        if fps_counter % 30 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            fps = 30 / elapsed\n",
    "            start_time = time.time()\n",
    "        \n",
    "        # 9. Display FPS\n",
    "        cv2.putText(frame, f'FPS: {fps:.1f}', (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        # 10. Show frame\n",
    "        cv2.imshow('People Counting System', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Final statistics\n",
    "    final_counts = counter.get_counts()\n",
    "    print(f\"\\nüìä Final Statistics:\")\n",
    "    print(f\"   ‚Ä¢ People IN: {final_counts['in']}\")\n",
    "    print(f\"   ‚Ä¢ People OUT: {final_counts['out']}\")\n",
    "    print(f\"   ‚Ä¢ Current occupancy: {final_counts['current']}\")\n",
    "    print(f\"   ‚Ä¢ Total crossings: {final_counts['total']}\")\n",
    "    print(f\"   ‚Ä¢ Average FPS: {fps:.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945db8e-29cd-42b5-8fc4-d1ec55ec4295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
